{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Data selection and preprocessing\n",
    "\n",
    "1st step : selection and separation of data\n",
    "\n",
    "-> In order to represent all the 7 classes, we are going to select the maximum out of the less represented ones \n",
    "\n",
    "In march 2024, the available data consists of this : \n",
    "\n",
    "Plastique 22996\n",
    "Mégots 2827\n",
    "Papier ou Carton 9061\n",
    "Textile 1446\n",
    "Métaux 13424\n",
    "Verre 4709\n",
    "Matières Organiques 338\n",
    "\n",
    "For the first experiments, we selected up to 2000 images of each class (not randomly, see select_data from data_processing)\n",
    "\n",
    "Starting from a raw file, we select the filenames we want the model to train on\n",
    "\n",
    "\n",
    "-> We load this images and sort it into different folders this way : \n",
    "\n",
    "data/\n",
    "    -Verre/\n",
    "        --Verre01\n",
    "        --Verre02\n",
    "        ...\n",
    "    -Mégots/\n",
    "        --Mégots01\n",
    "        --Mégots02\n",
    "        ...\n",
    "    ...\n",
    "\n",
    "-> Then we separate it into train, test and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '../../../../Trashback2000_620v2'\n",
    "excel_path = '/Users/macbook/Desktop/waste_pics.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = \"/Users/macbook/Desktop/Trashback\" # the full quality images\n",
    "size=(620,620)\n",
    "output_folder = '/Users/macbook/Desktop/Trashback_resized_resnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import import_excel_from_local, create_dictionnaries\n",
    "\n",
    "excel_data = import_excel_from_local(excel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CREATED</th>\n",
       "      <th>PIC_NAME</th>\n",
       "      <th>WASTE_TYPE</th>\n",
       "      <th>WASTE_SUB_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-07-18 02:41:23</td>\n",
       "      <td>1689655283310-image1689655288912.jpg</td>\n",
       "      <td>Plastique</td>\n",
       "      <td>Bouteille en plastique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-07-18 03:03:52</td>\n",
       "      <td>1689656632003-image1689656604097.jpg</td>\n",
       "      <td>Mégots</td>\n",
       "      <td>Mégots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-07-18 03:04:23</td>\n",
       "      <td>1689656663316-image1689656670630.jpg</td>\n",
       "      <td>Papier ou Carton</td>\n",
       "      <td>Récipient liquide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-07-18 03:07:22</td>\n",
       "      <td>1689656842073-image1689656841084.jpg</td>\n",
       "      <td>Mégots</td>\n",
       "      <td>Mégots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-07-18 03:10:33</td>\n",
       "      <td>1689657033386-image1689657030920.jpg</td>\n",
       "      <td>Plastique</td>\n",
       "      <td>Polystyrène</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              CREATED  ...          WASTE_SUB_TYPE\n",
       "0 2023-07-18 02:41:23  ...  Bouteille en plastique\n",
       "1 2023-07-18 03:03:52  ...                  Mégots\n",
       "2 2023-07-18 03:04:23  ...       Récipient liquide\n",
       "3 2023-07-18 03:07:22  ...                  Mégots\n",
       "4 2023-07-18 03:10:33  ...             Polystyrène\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_files,image_labels,image_sub_labels = create_dictionnaries(excel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can also directly import the dictionnaries\n",
    "\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "with open('category_files.json', 'r') as fp:\n",
    "        category_files = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plastique 22996\n",
      "Mégots 2827\n",
      "Papier ou Carton 9061\n",
      "Textile 1446\n",
      "Métaux 13424\n",
      "Verre 4709\n",
      "Matières Organiques 338\n"
     ]
    }
   ],
   "source": [
    "for category in category_files.keys():\n",
    "    print(category,len(category_files[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_selection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#from data_processing import select_data\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m category_files \u001b[38;5;241m=\u001b[39m \u001b[43mdata_selection\u001b[49m(\u001b[38;5;241m2000\u001b[39m,category_files) \u001b[38;5;66;03m# this is not random !!\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m category \u001b[38;5;129;01min\u001b[39;00m category_files\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(category,\u001b[38;5;28mlen\u001b[39m(category_files[category]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_selection' is not defined"
     ]
    }
   ],
   "source": [
    "#from data_processing import select_data\n",
    "\n",
    "category_files = data_selection(2000,category_files) # this is not random !!\n",
    "for category in category_files.keys():\n",
    "    print(category,len(category_files[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_resizing_pipeline import resize_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "resize_images() got an unexpected keyword argument 'filenames_to_sort'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m     filenames \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m category_files[category]\n\u001b[1;32m      5\u001b[0m input_folder \u001b[38;5;241m=\u001b[39m raw_data_path\n\u001b[0;32m----> 7\u001b[0m \u001b[43mresize_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames_to_sort\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: resize_images() got an unexpected keyword argument 'filenames_to_sort'"
     ]
    }
   ],
   "source": [
    "filenames = []\n",
    "for category in category_files.keys():\n",
    "    filenames += category_files[category]\n",
    "\n",
    "input_folder = raw_data_path\n",
    "\n",
    "resize_images(input_folder, output_folder, size, filenames_to_sort = filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our images (max 2000 per class) in our folder (output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import sort_local_file\n",
    "\n",
    "file_to_sort = output_folder\n",
    "\n",
    "sort_local_file(file_to_sort,category_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_resnet import make_train_valid_test_data\n",
    "DATASET_PATH = file_to_sort\n",
    "train_data,valid_data,test_data = make_train_valid_test_data(DATASET_PATH,size=(620,620))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_resnet import make_loader\n",
    "\n",
    "train_loader = make_loader(train_data, batch_size=10, shuffle=True)\n",
    "val_loader = make_loader(val_data, batch_size=10)\n",
    "test_loader = make_loader(test_data, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now everything is ready for training, we can show some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, label):\n",
    "    plt.title(f\"label: {label}, {LABELS[label]}\\n\")\n",
    "    plt.imshow(transforms.ToPILImage()(image).convert('RGB'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_data[0]\n",
    "show_image(image, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Now the training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mclass_to_idx)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "print(train_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = train_dataset.classes\n",
    "num_class = len(LABELS)\n",
    "\n",
    "\n",
    "from train_resnet import create_model,train\n",
    "\n",
    "models = ['Resnet','Resnext']\n",
    "\n",
    "model = create_model(num_class,model_type=models[0])\n",
    "\n",
    "\n",
    "trainer = train(train_loader,val_loader,model,max_epochs=25, limit_train_batches=100,default_root_dir='./logs/resnet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can evaluate the model on the test set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_resnet import test,print_confusion_matrix\n",
    "\n",
    "test(trainer,model,test_loader,ckpt_path='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_checkpoints = \n",
    "\n",
    "print_confusion_matrix(path_to_checkpoints)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

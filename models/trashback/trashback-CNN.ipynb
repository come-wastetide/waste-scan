{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate\n",
    "from pathlib import Path\n",
    "from glob2 import glob\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile as zf\n",
    "import shutil\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import boto3\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "from data_processing import sort_images, binary_search\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_and_subcategory(filenames,key):\n",
    "    \n",
    "    filename = key.split('/')[-1]\n",
    "\n",
    "    # we are going to do a binary search to find the filename in the excel file\n",
    "\n",
    "    index = binary_search(filenames, filename)\n",
    "    \n",
    "    i = index\n",
    "\n",
    "    row = excel_data[index:index+1]\n",
    "    category = row['WASTE_TYPE'][i]\n",
    "    sub_category = row['WASTE_SUB_TYPE'][i]\n",
    "\n",
    "    return category,sub_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting 6411 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 6411/6411 [59:46<00:00,  1.79images/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images sorted successfully.\n"
     ]
    }
   ],
   "source": [
    "from data_processing import sort_images, binary_search\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'trashback-data'\n",
    "excel_file_key = 'waste_pics.xlsx'\n",
    "image_folder_key = 'trashback-images/'\n",
    "target_folder_name = 'sorted_images_test/'\n",
    "\n",
    "sort_images(bucket_name,image_folder_key,target_folder_name,excel_file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder_names_from_excel(excel_data):\n",
    "\n",
    "    '''\n",
    "\n",
    "    input : excel_data with 'WASTE_TYPE' and 'WASTE_SUB_TYPE' in the keys\n",
    "\n",
    "    output : folder_names \n",
    "\n",
    "    '''\n",
    "\n",
    "    folder_names = []\n",
    "    excel_data.dropna()\n",
    "\n",
    "    for i in range(45080):\n",
    "        category = excel_data['WASTE_TYPE'][i]\n",
    "        sub_cat = excel_data['WASTE_SUB_TYPE'][i]\n",
    "\n",
    "        folder_name = str(category) + '/' + str(sub_cat) + '/'\n",
    "        if folder_name not in folder_names:\n",
    "            folder_names.append(folder_name)\n",
    "\n",
    "    return folder_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folders_if_needed(folder_name,folder_names):\n",
    "    '''\n",
    "\n",
    "    input : a list of folder names, with category & subcategory : 'Plastique/Autre déchet plastique/\n",
    "\n",
    "    output : nothing but created the folders if not in the s3 bucket (within sorted images)\n",
    "\n",
    "    ''' \n",
    "\n",
    "    for string in folder_names:\n",
    "        category,sub_category = string.split('/')[0],string.split('/')[1]\n",
    "\n",
    "        try:\n",
    "            s3.head_object(Bucket=bucket_name, Key=f'{folder_name}/{category}/')\n",
    "        except s3.exceptions.ClientError as e:\n",
    "            if e.response['Error']['Code'] == '404':\n",
    "                s3.put_object(Bucket=bucket_name, Key=f'{folder_name}/{category}/', Body='')\n",
    "\n",
    "        # Create \"sub-category\" folder if it does not exist\n",
    "\n",
    "        try:\n",
    "            s3.head_object(Bucket=bucket_name, Key=f'{folder_name}/{category}/{sub_category}')\n",
    "        except s3.exceptions.ClientError as e:\n",
    "            if e.response['Error']['Code'] == '404':\n",
    "                s3.put_object(Bucket=bucket_name, Key=f'{folder_name}/{category}/{sub_category}', Body='')\n",
    "\n",
    "    print(\"Folders created successfully.\")\n",
    "#create_folders_if_needed(folder_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-20 10:50:11.801194: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'trashback-data'\n",
    "test_folder_key = 'sorted_images_test/'\n",
    "train_folder_key = 'sorted_images/'\n",
    "excel_file_key = 'waste_pics.xlsx'\n",
    "\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "excel_obj = s3.get_object(Bucket=bucket_name, Key=excel_file_key)\n",
    "excel_data = pd.read_excel(io.BytesIO(excel_obj['Body'].read()))\n",
    "\n",
    "\n",
    "categories = create_folder_names_from_excel(excel_data)  #methode longue pour extraire les categories\n",
    "num_classes = len(categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to creat a dictionnary with the categories\n",
    "\n",
    "categories_dict = {}\n",
    "categories = excel_data['WASTE_TYPE'].unique()\n",
    "\n",
    "for i in range(45080):\n",
    "    category = excel_data['WASTE_TYPE'][i]\n",
    "    sub_cat = excel_data['WASTE_SUB_TYPE'][i]\n",
    "\n",
    "    folder_name = str(category) + '/' + str(sub_cat) + '/'\n",
    "    if folder_name not in categories_dict:\n",
    "        categories_dict[folder_name] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to create a dictionary with the keys of images as well as their category\n",
    "from data_processing import list_keys\n",
    "\n",
    "def create_dict_of_images(bucket_name,folder_key,excel_data):\n",
    "\n",
    "    keys = list_keys(bucket_name,folder_key)\n",
    "\n",
    "    dict_of_images = {}\n",
    "    keys = []\n",
    "    \n",
    "\n",
    "    for key in keys:\n",
    "        category,sub_category = get_category_and_subcategory(excel_data,key)\n",
    "        dict_of_images[key] = category + '/' + sub_category\n",
    "\n",
    "    return dict_of_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import list_keys\n",
    "\n",
    "keys = list_keys(bucket_name,train_folder_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_images = {}\n",
    "dict_filenames = {}\n",
    "\n",
    "for key in keys:\n",
    "    filename = key.split('/')[-1]\n",
    "    category,sub_category = key.split('/')[-3],key.split('/')[-2]\n",
    "    dict_of_images[key] = category + '/' + sub_category\n",
    "    dict_filenames[filename] = category + '/' + sub_category\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to convert this dictionnaire into a dataframe\n",
    "\n",
    "df = pd.DataFrame(list(dict_of_images.items()),columns = ['path','category'])\n",
    "df2 = pd.DataFrame(list(dict_filenames.items()),columns = ['filename','category'])\n",
    "\n",
    "#we shuffle the dataframe\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df2 = df2.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data,ratio):\n",
    "    last=int(len(data)*ratio)\n",
    "    return data[:last], data[last:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/Users/macbook/Desktop/Trashback/'\n",
    "\n",
    "df2['filename'] = base_path + df2['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=split_data(df2,.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv',index=False)\n",
    "test.to_csv('test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we remove the lines of the dataframe that are not in the category list\n",
    "\n",
    "train = train[(train['category']+'/').isin(categories)]\n",
    "test = test[(test['category']+'/').isin(categories)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Métaux/Canette                                    3445\n",
       "Plastique/Bouteille en plastique                  2568\n",
       "Plastique/Autre déchet plastique                  2261\n",
       "Plastique/Emballage plastique                     2245\n",
       "Métaux/Autre déchet métaux                        1142\n",
       "Verre/Bouteille en verre                          1141\n",
       "Mégots/Mégots                                      813\n",
       "Papier ou Carton/Carton                            681\n",
       "Plastique/Sac en plastique                         545\n",
       "Plastique/Bouchon en plastique                     394\n",
       "Papier ou Carton/Récipient liquide                 333\n",
       "Papier ou Carton/Emballage bonbon                  310\n",
       "Plastique/Polystyrène                              298\n",
       "Verre/< 10 morceaux de verre                       267\n",
       "Papier ou Carton/Ticket                            258\n",
       "Papier ou Carton/Sac en papier                     239\n",
       "Mégots/< 10 mégots                                 238\n",
       "Plastique/Gobelet en plastique                     221\n",
       "Textile/Autre déchet textile                       204\n",
       "Mégots/~ 25 mégots                                 142\n",
       "Textile/Vêtement                                   140\n",
       "Textile/Masque                                     140\n",
       "Métaux/Conserve                                    132\n",
       "Papier ou Carton/Journaux                          127\n",
       "Textile/Corde                                      113\n",
       "Verre/Autre déchet verre                           101\n",
       "Mégots/~ 200 mégots                                 87\n",
       "Plastique/Briquet                                   81\n",
       "Matières Organiques/Autre déchet organique          69\n",
       "Verre/Pot en verre                                  68\n",
       "Métaux/Cable                                        56\n",
       "Mégots/~ 400 mégots                                 49\n",
       "Mégots/~ 50 mégots                                  45\n",
       "Métaux/Pile                                         42\n",
       "Mégots/~ 75 mégots                                  41\n",
       "Verre/~ 50 morceaux de verre                        36\n",
       "Verre/> 50 morceaux de verre                        33\n",
       "Métaux/Cartouche chasse                             33\n",
       "Textile/Chaussure                                   32\n",
       "Plastique/Capsule                                   31\n",
       "Métaux/Materiel informatique                        19\n",
       "Matières Organiques/Pelure de fruit                 15\n",
       "Mégots/+ 500 mégots                                 12\n",
       "Plastique/Carte                                     12\n",
       "Textile/Couche                                      10\n",
       "Verre/Ampoule                                        7\n",
       "Matières Organiques/Pelure de légume                 7\n",
       "Papier ou Carton/Autre déchet papier ou carton       5\n",
       "Plastique/Carton                                     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Métaux/Canette                                899\n",
       "Plastique/Bouteille en plastique              663\n",
       "Plastique/Autre déchet plastique              542\n",
       "Plastique/Emballage plastique                 533\n",
       "Métaux/Autre déchet métaux                    312\n",
       "Verre/Bouteille en verre                      272\n",
       "Mégots/Mégots                                 201\n",
       "Papier ou Carton/Carton                       174\n",
       "Plastique/Sac en plastique                    125\n",
       "Plastique/Bouchon en plastique                110\n",
       "Papier ou Carton/Emballage bonbon              83\n",
       "Papier ou Carton/Récipient liquide             83\n",
       "Papier ou Carton/Ticket                        66\n",
       "Verre/< 10 morceaux de verre                   66\n",
       "Mégots/< 10 mégots                             62\n",
       "Plastique/Polystyrène                          62\n",
       "Plastique/Gobelet en plastique                 62\n",
       "Textile/Autre déchet textile                   55\n",
       "Papier ou Carton/Sac en papier                 51\n",
       "Mégots/~ 25 mégots                             39\n",
       "Textile/Corde                                  35\n",
       "Textile/Masque                                 34\n",
       "Verre/Autre déchet verre                       32\n",
       "Plastique/Briquet                              29\n",
       "Papier ou Carton/Journaux                      25\n",
       "Textile/Vêtement                               23\n",
       "Mégots/~ 200 mégots                            23\n",
       "Métaux/Conserve                                20\n",
       "Plastique/Capsule                              16\n",
       "Matières Organiques/Autre déchet organique     14\n",
       "Verre/Pot en verre                             14\n",
       "Métaux/Pile                                    13\n",
       "Verre/> 50 morceaux de verre                   12\n",
       "Métaux/Cable                                   11\n",
       "Mégots/~ 50 mégots                             10\n",
       "Textile/Chaussure                               8\n",
       "Verre/~ 50 morceaux de verre                    7\n",
       "Mégots/~ 75 mégots                              7\n",
       "Mégots/~ 400 mégots                             7\n",
       "Métaux/Cartouche chasse                         7\n",
       "Matières Organiques/Pelure de fruit             6\n",
       "Métaux/Materiel informatique                    4\n",
       "Mégots/+ 500 mégots                             3\n",
       "Verre/Ampoule                                   2\n",
       "Textile/Couche                                  2\n",
       "Mégots/Autre déchet papier ou carton            1\n",
       "Plastique/Carte                                 1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,valid=split_data(train,.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/macbook/Desktop/Trashback/1690890272647-image1690890265729.jpg</td>\n",
       "      <td>Métaux/Canette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/macbook/Desktop/Trashback/1697531309273-user.jpg</td>\n",
       "      <td>Verre/&lt; 10 morceaux de verre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/macbook/Desktop/Trashback/1689932864492-user.jpg</td>\n",
       "      <td>Plastique/Bouteille en plastique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/macbook/Desktop/Trashback/1694002474287-image1694002399218.jpg</td>\n",
       "      <td>Mégots/Mégots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/macbook/Desktop/Trashback/1689870910900-image1689870876332.jpg</td>\n",
       "      <td>Mégots/Mégots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18886</th>\n",
       "      <td>/Users/macbook/Desktop/Trashback/1690797034541-image1690797012818.jpg</td>\n",
       "      <td>Plastique/Sac en plastique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18887</th>\n",
       "      <td>/Users/macbook/Desktop/Trashback/1696784502253-image1696784507143.jpg</td>\n",
       "      <td>Papier ou Carton/Ticket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18888</th>\n",
       "      <td>/Users/macbook/Desktop/Trashback/1689865671335-image1689865691067.jpg</td>\n",
       "      <td>Métaux/Canette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18889</th>\n",
       "      <td>/Users/macbook/Desktop/Trashback/1698375594892-image1698375620046.jpg</td>\n",
       "      <td>Plastique/Emballage plastique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18891</th>\n",
       "      <td>/Users/macbook/Desktop/Trashback/1695059804185-user.jpg</td>\n",
       "      <td>Plastique/Bouteille en plastique</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17360 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    filename  \\\n",
       "0      /Users/macbook/Desktop/Trashback/1690890272647-image1690890265729.jpg   \n",
       "1                    /Users/macbook/Desktop/Trashback/1697531309273-user.jpg   \n",
       "2                    /Users/macbook/Desktop/Trashback/1689932864492-user.jpg   \n",
       "3      /Users/macbook/Desktop/Trashback/1694002474287-image1694002399218.jpg   \n",
       "4      /Users/macbook/Desktop/Trashback/1689870910900-image1689870876332.jpg   \n",
       "...                                                                      ...   \n",
       "18886  /Users/macbook/Desktop/Trashback/1690797034541-image1690797012818.jpg   \n",
       "18887  /Users/macbook/Desktop/Trashback/1696784502253-image1696784507143.jpg   \n",
       "18888  /Users/macbook/Desktop/Trashback/1689865671335-image1689865691067.jpg   \n",
       "18889  /Users/macbook/Desktop/Trashback/1698375594892-image1698375620046.jpg   \n",
       "18891                /Users/macbook/Desktop/Trashback/1695059804185-user.jpg   \n",
       "\n",
       "                               category  \n",
       "0                        Métaux/Canette  \n",
       "1          Verre/< 10 morceaux de verre  \n",
       "2      Plastique/Bouteille en plastique  \n",
       "3                         Mégots/Mégots  \n",
       "4                         Mégots/Mégots  \n",
       "...                                 ...  \n",
       "18886        Plastique/Sac en plastique  \n",
       "18887           Papier ou Carton/Ticket  \n",
       "18888                    Métaux/Canette  \n",
       "18889     Plastique/Emballage plastique  \n",
       "18891  Plastique/Bouteille en plastique  \n",
       "\n",
       "[17360 rows x 2 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are going to convert paths into s3 urls\n",
    "\n",
    "def convert_to_s3_url(bucket_name,df):\n",
    "    df['path'] = 's3://' + bucket_name + '/' + df['path']\n",
    "    return df\n",
    "\n",
    "train = convert_to_s3_url(bucket_name,train)\n",
    "valid = convert_to_s3_url(bucket_name,valid)\n",
    "test = convert_to_s3_url(bucket_name,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17359 validated image filenames.\n",
      "Found 1929 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbook/Desktop/WasteScan/waste-scan/venv/lib/python3.11/site-packages/keras/src/preprocessing/image.py:1137: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "batch_size = 16\n",
    "size=224\n",
    "epoch=50\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train,\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=(size, size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"input\"\n",
    "    )\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=valid,\n",
    "    x_col='filename',\n",
    "    y_col='category',\n",
    "    target_size=(size, size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"input\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/macbook/Desktop/Trashback/1690890272647-image1690890265729.jpg</td>\n",
       "      <td>Métaux/Canette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/macbook/Desktop/Trashback/1697531309273-user.jpg</td>\n",
       "      <td>Verre/&lt; 10 morceaux de verre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/macbook/Desktop/Trashback/1689932864492-user.jpg</td>\n",
       "      <td>Plastique/Bouteille en plastique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/macbook/Desktop/Trashback/1694002474287-image1694002399218.jpg</td>\n",
       "      <td>Mégots/Mégots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/macbook/Desktop/Trashback/1689870910900-image1689870876332.jpg</td>\n",
       "      <td>Mégots/Mégots</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                filename  \\\n",
       "0  /Users/macbook/Desktop/Trashback/1690890272647-image1690890265729.jpg   \n",
       "1                /Users/macbook/Desktop/Trashback/1697531309273-user.jpg   \n",
       "2                /Users/macbook/Desktop/Trashback/1689932864492-user.jpg   \n",
       "3  /Users/macbook/Desktop/Trashback/1694002474287-image1694002399218.jpg   \n",
       "4  /Users/macbook/Desktop/Trashback/1689870910900-image1689870876332.jpg   \n",
       "\n",
       "                           category  \n",
       "0                    Métaux/Canette  \n",
       "1      Verre/< 10 morceaux de verre  \n",
       "2  Plastique/Bouteille en plastique  \n",
       "3                     Mégots/Mégots  \n",
       "4                     Mégots/Mégots  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/macbook/Desktop/Trashback/1690890272647-image1690890265729.jpg</td>\n",
       "      <td>Métaux/Canette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/macbook/Desktop/Trashback/1697531309273-user.jpg</td>\n",
       "      <td>Verre/&lt; 10 morceaux de verre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/macbook/Desktop/Trashback/1689932864492-user.jpg</td>\n",
       "      <td>Plastique/Bouteille en plastique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/macbook/Desktop/Trashback/1694002474287-image1694002399218.jpg</td>\n",
       "      <td>Mégots/Mégots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/macbook/Desktop/Trashback/1689870910900-image1689870876332.jpg</td>\n",
       "      <td>Mégots/Mégots</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                filename  \\\n",
       "0  /Users/macbook/Desktop/Trashback/1690890272647-image1690890265729.jpg   \n",
       "1                /Users/macbook/Desktop/Trashback/1697531309273-user.jpg   \n",
       "2                /Users/macbook/Desktop/Trashback/1689932864492-user.jpg   \n",
       "3  /Users/macbook/Desktop/Trashback/1694002474287-image1694002399218.jpg   \n",
       "4  /Users/macbook/Desktop/Trashback/1689870910900-image1689870876332.jpg   \n",
       "\n",
       "                           category  \n",
       "0                    Métaux/Canette  \n",
       "1      Verre/< 10 morceaux de verre  \n",
       "2  Plastique/Bouteille en plastique  \n",
       "3                     Mégots/Mégots  \n",
       "4                     Mégots/Mégots  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n",
    "                        Permute, TimeDistributed, GlobalAveragePooling2D, SeparableConv2D,\\\n",
    "ZeroPadding2D, Convolution2D, ZeroPadding2D, Conv2DTranspose,ReLU, UpSampling2D, Concatenate, Conv2DTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_block_enc(inputs,alpha):\n",
    "    input_channels = inputs.shape[-1]\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n",
    "    x = tf.keras.layers.Dense(units=alpha, activation=\"relu\")(x)    \n",
    "    x = tf.keras.layers.Dense(units=input_channels, activation=\"sigmoid\")(x)    \n",
    "    x = tf.reshape(x, [-1, 1, 1, input_channels])\n",
    "    x = inputs * x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ENCODER\n",
    "input_img = Input(shape=(size,size, 3))  \n",
    "x = Conv2D(48, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x=se_block_enc(x,20)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(96, (3, 3), activation='relu', padding='same')(x)\n",
    "x=se_block_enc(x,30)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(192, (3, 3), activation='relu', padding='same')(x)\n",
    "x=se_block_enc(x,50)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "encoded = Conv2D(32, (1, 1), activation='relu', padding='same')(x)\n",
    "\n",
    "# Bottolneck\n",
    "latentSize = (28,28,32)\n",
    "\n",
    "# DECODER\n",
    "direct_input = Input(shape=latentSize)\n",
    "x = Conv2D(192, (1, 1), activation='relu', padding='same')(direct_input)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(192, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(96, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(48, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(192, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "# COMPILE\n",
    "encoder = Model(input_img, encoded)\n",
    "decoder = Model(direct_input, decoded)\n",
    "autoencoder = Model(input_img, decoder(encoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 224, 224, 48)         1344      ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling2d (  (None, 48)                   0         ['conv2d_1[0][0]']            \n",
      " GlobalAveragePooling2D)                                                                          \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 20)                   980       ['global_average_pooling2d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 48)                   1008      ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)     (None, 1, 1, 48)             0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLamb  (None, 224, 224, 48)         0         ['conv2d_1[0][0]',            \n",
      " da)                                                                 'tf.reshape[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 112, 112, 48)         0         ['tf.math.multiply[0][0]']    \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 112, 112, 96)         41568     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1  (None, 96)                   0         ['conv2d_2[0][0]']            \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 30)                   2910      ['global_average_pooling2d_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 96)                   2976      ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " tf.reshape_1 (TFOpLambda)   (None, 1, 1, 96)             0         ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLa  (None, 112, 112, 96)         0         ['conv2d_2[0][0]',            \n",
      " mbda)                                                               'tf.reshape_1[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 56, 56, 96)           0         ['tf.math.multiply_1[0][0]']  \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 56, 56, 192)          166080    ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2  (None, 192)                  0         ['conv2d_3[0][0]']            \n",
      "  (GlobalAveragePooling2D)                                                                        \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 50)                   9650      ['global_average_pooling2d_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 192)                  9792      ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " tf.reshape_2 (TFOpLambda)   (None, 1, 1, 192)            0         ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLa  (None, 56, 56, 192)          0         ['conv2d_3[0][0]',            \n",
      " mbda)                                                               'tf.reshape_2[0][0]']        \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 28, 28, 192)          0         ['tf.math.multiply_2[0][0]']  \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 32)           6176      ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " model_1 (Functional)        (None, 224, 224, 3)          634131    ['conv2d_4[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 876615 (3.34 MB)\n",
      "Trainable params: 876615 (3.34 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'autoencoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mlegacy\u001b[38;5;241m.\u001b[39mAdam(), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m history \u001b[38;5;241m=\u001b[39m autoencoder\u001b[38;5;241m.\u001b[39mfit_generator(train_generator,\n\u001b[1;32m      3\u001b[0m                                  validation_data\u001b[38;5;241m=\u001b[39m valid_generator,\n\u001b[1;32m      4\u001b[0m         epochs \u001b[38;5;241m=\u001b[39m epoch, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'autoencoder' is not defined"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(optimizer=tf.keras.optimizers.legacy.Adam(), loss='binary_crossentropy')\n",
    "history = autoencoder.fit_generator(train_generator,\n",
    "                                 validation_data= valid_generator,\n",
    "        epochs = epoch, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
